<!DOCTYPE html>
<html lang="en">
<head>
    <title>Learning Tracker</title>
    <link href="css/style.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js" integrity="sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4" crossorigin="anonymous" type=""></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js" integrity="sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa" crossorigin="anonymous"
            onload="renderMathInElement(document.body);"></script>
    <link href="https://fonts.googleapis.com/css?family=Frank+Ruhl+Libre|Roboto" rel="stylesheet">
    <link href="css/normalize.css" rel="stylesheet" type="text/css" />
    <link href="css/toc.css" rel="stylesheet" type="text/css" />
    <link href="css/spoiler.css" rel="stylesheet" type="text/css" />
</head>

<body>

<div id="bump">
    <header class="site-header darken">
        <div class="wrap">
            <hgroup>
                <h1> Alexey Tochin </h1>
            </hgroup>
            <a class="nav menu" href="#"><span class='icons'>â˜°</span></a>
            <nav role="navigation">
                <ul>
                    <li><a href="index.html"> Home </a></li>
                    <li><a href="machine_learning.html"> ML </a></li>
                    <li><a href="other_topics.html"> Not ML </a></li>
                    <li><a href="about.html"> About </a></li>
                    <li><a href="references.html"> References </a></li>
                </ul>
            </nav>
        </div>
    </header>
</div>

<section class="article archive">
    <article class="archive-wrap">
        <header class="post-header"><hgroup><h1> Machine learning articles </h1></hgroup></header>
        <ol class="post-list">
            <hr>
            <li class="slider">
                <img src="posts/batch_size_vs_momentum/images/icon.png" alt="" height="200" width="200" class=hp />
                <div class="deets left-slide">
                    <h1>
                        <a href="posts/batch_size_vs_momentum/batch_size_vs_momentum.html">
                            Batch size vs Momentum
                        </a>
                    </h1>
                    <p></p>
                    <p class="abstract">
                        Suppose we found an optimal learning rate and other hyperparameters for a gradient descent method and for a certain model.
                        A typical next step is to train the model on a more power hardware with more GPU units and GPU RAM that supports bigger batch size.
                        How should we scale up the gradient descent hyperparameters and do not knock down the settings?
                        We address this question and
                        some familiar ones in this article.
                        The main thesis:
                        <em>batch size change is approximately equivalent to a certain shift of learning rate and momentum</em>.
                    </p>
                    <p class="date">
                        published 8.04.2021, last update 30.07.2021
                    </p>
                </div>
            </li>
            <hr>
        </ol>
    </article>
</section>